{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext as thtext\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = th.device('cuda:3')\n",
    "th.cuda.set_device(device=cuda_device)\n",
    "\n",
    "base_path = '/data/blchen/text/CCKS2019-IPRE/'\n",
    "save_path = os.path.join(base_path, 'preprocessed/sent')\n",
    "result_path = os.path.join(base_path, 'result')\n",
    "test_path = os.path.join(base_path, 'sent_relation_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(save_path, 'X_train.npy'))\n",
    "X_dev = np.load(os.path.join(save_path, 'X_dev.npy'))\n",
    "\n",
    "y_train = scipy.sparse.load_npz(os.path.join(save_path, 'y_train.npz'))\n",
    "y_dev = scipy.sparse.load_npz(os.path.join(save_path, 'y_dev.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = th.LongTensor(X_train)\n",
    "X_dev = th.LongTensor(X_dev)\n",
    "\n",
    "y_train = th.FloatTensor(y_train.todense())\n",
    "y_dev = th.FloatTensor(y_dev.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape torch.Size([500, 50]) y_train shape torch.Size([500, 35])\n",
      "train_batch_num 575\n",
      "X_dev shape torch.Size([1000, 50]) y_dev shape torch.Size([1000, 35])\n",
      "dev_batch_num 39\n",
      "train/dev split 0.8820725178654748\n"
     ]
    }
   ],
   "source": [
    "train_dataset = th.utils.data.TensorDataset(X_train, y_train)\n",
    "train_data_loader = th.utils.data.DataLoader(train_dataset, batch_size=500, shuffle=True)\n",
    "\n",
    "dev_dataset = th.utils.data.TensorDataset(X_dev, y_dev)\n",
    "dev_data_loader = th.utils.data.DataLoader(dev_dataset, batch_size=1000)\n",
    "\n",
    "for X_train_batch, y_train_batch in train_data_loader:\n",
    "    print('X_train shape', X_train_batch.shape, 'y_train shape', y_train_batch.shape)\n",
    "    break\n",
    "print('train_batch_num', len(train_data_loader))\n",
    "for X_dev_batch, y_dev_batch in dev_data_loader:\n",
    "    print('X_dev shape', X_dev_batch.shape, 'y_dev shape', y_dev_batch.shape)\n",
    "    break\n",
    "print('dev_batch_num', len(dev_data_loader))\n",
    "print('train/dev split', len(X_train)/(len(X_train) + len(X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EXAM(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num=50, label_num=35, hidden_size=1024, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embed = nn.Embedding(270734, 300, padding_idx=0)\n",
    "        self.label_embed = nn.Parameter(th.Tensor(label_num, hidden_size*2))\n",
    "        \n",
    "        self.rnn = nn.LSTM(300, hidden_size, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.dense_1 = nn.Linear(feature_num, feature_num*2)\n",
    "        self.dense_2 = nn.Linear(feature_num*2, 1)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x)\n",
    "        encode = self.rnn(embed)[0]\n",
    "        \n",
    "        interaction = th.matmul(encode, self.label_embed.transpose(0, 1)).transpose(1, 2)\n",
    "        \n",
    "        out = F.relu(self.dense_1(interaction))\n",
    "        out = self.dense_2(out).squeeze(dim=-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = EXAM()\n",
    "net = net.to(cuda_device)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optim = th.optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(th.load('/data/blchen/text/CCKS2019-IPRE/net/sent/30.pt', \n",
    "                            map_location=lambda storage, loc: storage.cuda(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_k(pred, label, k=[1, 3, 5]):\n",
    "    batch_size = pred.shape[0]\n",
    "    \n",
    "    precision = []\n",
    "    for _k in k:\n",
    "        p = 0\n",
    "        for i in range(batch_size):\n",
    "            p += label[i, pred[i, :_k]].mean().item()\n",
    "        precision.append(p*100/batch_size)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def evaluate(result):\n",
    "    p1, p3 = 0, 0\n",
    "    \n",
    "    with th.no_grad():\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(dev_data_loader):\n",
    "\n",
    "            _batch_size = X_batch.shape[0]\n",
    "            X_batch = X_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "\n",
    "            output = net(X_batch)\n",
    "            pred = output.topk(k=5)[1]\n",
    "\n",
    "            _p1, _p3 = precision_k(pred, y_batch, k=[1, 3])\n",
    "            p1 += _p1\n",
    "            p3 += _p3\n",
    "\n",
    "    \n",
    "    batch_idx += 1\n",
    "    p1 /= batch_idx\n",
    "    p3 /= batch_idx\n",
    "\n",
    "    result[-1].append([p1, p3])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(result):\n",
    "    f, p, r = 0, 0, 0\n",
    "    \n",
    "    with th.no_grad():\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(dev_data_loader):\n",
    "\n",
    "            _batch_size = X_batch.shape[0]\n",
    "            X_batch = X_batch.cuda()\n",
    "            y_batch = y_batch.numpy()\n",
    "\n",
    "            output = net(X_batch).topk(k=5)[1].cpu().numpy()\n",
    "            pred = np.zeros(y_batch.shape)\n",
    "            pred[output] = 1\n",
    "\n",
    "            _f = f1_score(y_batch, pred, average='micro')\n",
    "            _p = precision_score(y_batch, pred, average='micro')\n",
    "            _r = recall_score(y_batch, pred, average='micro')\n",
    "            f += _f\n",
    "            p += _p\n",
    "            r += _r\n",
    "\n",
    "    \n",
    "    batch_idx += 1\n",
    "    f /= batch_idx\n",
    "    p /= batch_idx\n",
    "    r /= batch_idx\n",
    "\n",
    "    result[-1].append([f, p, r])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for e in tqdm(range(1, 31)):\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_data_loader):\n",
    "        \n",
    "        X_batch = X_batch.cuda()\n",
    "        y_batch = y_batch.cuda()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        l = loss(net(X_batch), y_batch)\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    result.append(['epoch', e])\n",
    "    result = evaluate(result)\n",
    "    \n",
    "    th.save(net.state_dict(), '/data/blchen/text/CCKS2019-IPRE/net/sent/'+ str(e) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(os.path.join(save_path, 'X_test.npy'))\n",
    "X_test = th.LongTensor(X_test)\n",
    "\n",
    "test_data_loader = th.utils.data.DataLoader(X_test, batch_size=1000)\n",
    "\n",
    "for X_test_batch in test_data_loader:\n",
    "    print('X_train shape', X_test_batch.shape)\n",
    "    break\n",
    "print('train_batch_num', len(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(th.load('/data/blchen/text/CCKS2019-IPRE/net/sent/1.pt', \n",
    "                            map_location=lambda storage, loc: storage.cuda(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "with th.no_grad():\n",
    "    for batch_idx, X_batch in enumerate(test_data_loader):\n",
    "\n",
    "        _batch_size = X_batch.shape[0]\n",
    "        X_batch = X_batch.cuda()\n",
    "\n",
    "        output = net(X_batch)\n",
    "        pred = output.topk(k=1)[1]\n",
    "        for p in pred.tolist():\n",
    "            result.append(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in result:\n",
    "    if(r != 0):\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, 'r') as f:\n",
    "    with open(os.path.join(result_path, 'result-lstm-1.txt'), 'w') as fw:\n",
    "        cnt = 0\n",
    "        for line in f:\n",
    "            fw.write(line.strip() + '\\t' + str(result[cnt]) + '\\n')\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
