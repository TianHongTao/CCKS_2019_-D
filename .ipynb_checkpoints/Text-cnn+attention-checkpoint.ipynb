{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn import preprocessing\n",
    "from random import shuffle\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 401\n",
    "LABELNUMS = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(data1):\n",
    "    return (np.arange(LABELNUMS)==data1[:,None]).astype(np.integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.from_numpy(np.load(\"/Users/denhiroshi/Downloads/model_data/train_Sentense_np.npy\").astype(\"float32\"))\n",
    "train_Y = np.load(\"/Users/denhiroshi/Downloads/model_data/train_Relation_np.npy\").astype(\"int32\")\n",
    "dev_X = torch.from_numpy(np.load(\"/Users/denhiroshi/Downloads/model_data/dev_Sentense_np.npy\").astype(\"float32\"))\n",
    "dev_Y = np.load(\"/Users/denhiroshi/Downloads/model_data/dev_Relation_np.npy\").astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = train_Y.tolist()\n",
    "dev_Y = dev_Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot\n",
    "train_ontHot_y = []\n",
    "dev_ontHot_y = []\n",
    "for trainY in train_Y:\n",
    "    tmp = np.eye(LABELNUMS)[trainY]\n",
    "    tmp = tmp.sum(axis = 0).astype(\"int32\")\n",
    "    tmp = tmp[:-1]\n",
    "    train_ontHot_y.append(tmp)\n",
    "train_ontHot_y = torch.Tensor(train_ontHot_y)\n",
    "print(train_ontHot_y.shape)\n",
    "for devY in dev_Y:\n",
    "    tmp = np.eye(LABELNUMS)[devY]\n",
    "    tmp = tmp.sum(axis = 0).astype(\"int32\")\n",
    "    tmp = tmp[:-1]\n",
    "    dev_ontHot_y.append(tmp)\n",
    "dev_ontHot_y = torch.Tensor(dev_ontHot_y)\n",
    "print(dev_ontHot_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "class TEXTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEXTCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, BATCH_SIZE, 200)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=(1,200),\n",
    "            ), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(50,1)), \n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential( \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3,200), \n",
    "            ), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=(48,1)), \n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential( \n",
    "            nn.Conv2d(\n",
    "                in_channels=1, \n",
    "                out_channels=16, \n",
    "                kernel_size=(5,200), \n",
    "                stride = 1,\n",
    "            ), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(46,1)),\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Linear(48, LABELNUMS-1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1,1,x.shape[1],x.shape[2]))\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x = torch.cat((x1,x2,x3),1)\n",
    "        x = x.view(x.size(0), -1)   # 展平\n",
    "#         x = self.out(x)\n",
    "        output = self.output(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TEXTCNN()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"To GPU\")\n",
    "    train_X = train_X.cuda()\n",
    "    train_ontHot_y = train_ontHot_y.cuda()\n",
    "    dev_X = dev_X.cuda()\n",
    "    dev_ontHot_y = dev_ontHot_y.cuda()\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    print(\"Still CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(train_X, train_ontHot_y)\n",
    "dev = TensorDataset(dev_X, dev_ontHot_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 2, \n",
    ")\n",
    "\n",
    "\n",
    "dev_loader = DataLoader(\n",
    "    dataset = dev, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True, \n",
    "    num_workers = 2, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "loss_F = torch.nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "for epoch in range(1,EPOCHS): \n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        predict = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_F(sigmoid(predict), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.mean())\n",
    "    with torch.no_grad():\n",
    "        accs = []\n",
    "        for step,(devx,devy) in enumerate(dev_loader):\n",
    "            dev_pred = model(devx)\n",
    "            dev_pred = sigmoid(dev_pred)\n",
    "            tmp = dev_pred > 0.5\n",
    "            count = 0\n",
    "            for i in range(len(tmp.shape[0])):\n",
    "                if torch.sum(tmp.int()[i] == devy.int()[i]).tolist() == devy.shape[1]:\n",
    "                    count+=1\n",
    "            acc = count / devy.shape[0]\n",
    "            accs.append(acc)\n",
    "        print(f\"{epoch}: accuracy:{sum(accs)/len(accs)} loss: {torch.mean(torch.stack(losses))} time: {time.time() - start}\")\n",
    "    print(\"flag\")\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
