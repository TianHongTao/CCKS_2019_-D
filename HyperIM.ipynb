{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext as thtext\n",
    "import geoopt as gt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dtype = th.float64\n",
    "th.set_default_dtype(default_dtype)\n",
    "\n",
    "cuda_device = th.device('cuda:3')\n",
    "th.cuda.set_device(device=cuda_device)\n",
    "\n",
    "base_path = '/data/blchen/text/CCKS2019-IPRE/'\n",
    "save_path = os.path.join(base_path, 'preprocessed/sent')\n",
    "result_path = os.path.join(base_path, 'result')\n",
    "test_path = os.path.join(base_path, 'sent_relation_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(os.path.join(save_path, 'X_train.npy'))\n",
    "X_dev = np.load(os.path.join(save_path, 'X_dev.npy'))\n",
    "\n",
    "y_train = scipy.sparse.load_npz(os.path.join(save_path, 'y_train.npz'))\n",
    "y_dev = scipy.sparse.load_npz(os.path.join(save_path, 'y_dev.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = th.LongTensor(X_train)\n",
    "X_dev = th.LongTensor(X_dev)\n",
    "\n",
    "y_train = th.DoubleTensor(y_train.todense())\n",
    "y_dev = th.DoubleTensor(y_dev.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape torch.Size([4, 50]) y_train shape torch.Size([4, 35])\n",
      "train_batch_num 71838\n",
      "X_dev shape torch.Size([4, 50]) y_dev shape torch.Size([4, 35])\n",
      "dev_batch_num 9605\n",
      "train/dev split 0.8820725178654748\n"
     ]
    }
   ],
   "source": [
    "train_dataset = th.utils.data.TensorDataset(X_train, y_train)\n",
    "train_data_loader = th.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "dev_dataset = th.utils.data.TensorDataset(X_dev, y_dev)\n",
    "dev_data_loader = th.utils.data.DataLoader(dev_dataset, batch_size=4)\n",
    "\n",
    "for X_train_batch, y_train_batch in train_data_loader:\n",
    "    print('X_train shape', X_train_batch.shape, 'y_train shape', y_train_batch.shape)\n",
    "    break\n",
    "print('train_batch_num', len(train_data_loader))\n",
    "for X_dev_batch, y_dev_batch in dev_data_loader:\n",
    "    print('X_dev shape', X_dev_batch.shape, 'y_dev shape', y_dev_batch.shape)\n",
    "    break\n",
    "print('dev_batch_num', len(dev_data_loader))\n",
    "print('train/dev split', len(X_train)/(len(X_train) + len(X_dev)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_EPS = 1e-5\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "def project_hyp_vec(x):\n",
    "    # To make sure hyperbolic embeddings are inside the unit ball.\n",
    "    norm = th.sum(x**2, dim=-1, keepdim=True)\n",
    "    \n",
    "    return x * (1. - PROJ_EPS) / th.clamp(norm, 1. - PROJ_EPS)\n",
    "\n",
    "\n",
    "def asinh(x):\n",
    "    return th.log(x + (x**2 + 1)**0.5)\n",
    "\n",
    "\n",
    "def acosh(x):\n",
    "    return th.log(x + (x**2 - 1)**0.5)\n",
    "\n",
    "\n",
    "def atanh(x):\n",
    "    return 0.5*th.log((1 + x)/(1 - x))\n",
    "\n",
    "\n",
    "def poinc_dist(u, v):\n",
    "    m = mob_add(-u, v) + EPS\n",
    "    atanh_x = th.norm(m, dim=-1, keepdim=True)\n",
    "    dist_poincare = 2.0 * atanh(atanh_x)\n",
    "    return dist_poincare\n",
    "\n",
    "\n",
    "def euclid_dist(u, v):\n",
    "    return th.norm(u - v, dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "def mob_add(u, v):\n",
    "    v = v + EPS\n",
    "    \n",
    "    norm_uv = 2*th.sum(u*v, dim=-1, keepdim=True)\n",
    "    norm_u = th.sum(u**2, dim=-1, keepdim=True)\n",
    "    norm_v = th.sum(v**2, dim=-1, keepdim=True)\n",
    "    \n",
    "    denominator = 1 + norm_uv + norm_v * norm_u\n",
    "    result = (1 + norm_uv + norm_v)/denominator*u + (1 - norm_u)/denominator*v\n",
    "    \n",
    "    return project_hyp_vec(result)\n",
    "\n",
    "\n",
    "def mob_scalar_mul(r, v):\n",
    "    v = v + EPS\n",
    "    norm_v = th.norm(v, dim=-1, keepdim=True)\n",
    "    nomin = th.tanh(r*atanh(norm_v))\n",
    "    result = nomin/norm_v*v\n",
    "    \n",
    "    return project_hyp_vec(result)\n",
    "\n",
    "\n",
    "def mob_mat_mul(M, x):\n",
    "    x = project_hyp_vec(x)\n",
    "    Mx = x.matmul(M)\n",
    "    Mx_norm = th.norm(Mx + EPS, dim=-1, keepdim=True)\n",
    "    x_norm = th.norm(x + EPS, dim=-1, keepdim=True)\n",
    "    \n",
    "    return project_hyp_vec(th.tanh(Mx_norm/x_norm*atanh(x_norm)) / Mx_norm * Mx)\n",
    "\n",
    "\n",
    "def mob_mat_mul_d(M, x, d_ball):\n",
    "    x = project_hyp_vec(x)\n",
    "    Mx = x.view(x.shape[0], -1).matmul(M.view(M.shape[0]*d_ball,M.shape[0]*d_ball)).view(x.shape)\n",
    "    Mx_norm = th.norm(Mx + EPS, dim=-1, keepdim=True)\n",
    "    x_norm = th.norm(x + EPS, dim=-1, keepdim=True)\n",
    "    \n",
    "    return project_hyp_vec(th.tanh(Mx_norm/x_norm*atanh(x_norm)) / Mx_norm * Mx)\n",
    "\n",
    "\n",
    "def lambda_x(x):\n",
    "    return 2. / (1 - th.sum(x**2, dim=-1, keepdim=True))\n",
    "\n",
    "\n",
    "def exp_map_x(x, v):\n",
    "    v = v + EPS\n",
    "    second_term = th.tanh(lambda_x(x) * th.norm(v) / 2) / th.norm(v) * v\n",
    "    return mob_add(x, second_term)\n",
    "\n",
    "\n",
    "def log_map_x(x, y):\n",
    "    diff = mob_add(-x, y) + EPS\n",
    "    return 2. / lambda_x(x) * atanh(th.norm(diff, dim=-1, keepdim=True)) /\\\n",
    "            th.norm(diff, dim=-1, keepdim=True) * diff\n",
    "\n",
    "\n",
    "def exp_map_zero(v):\n",
    "    v = v + EPS\n",
    "    norm_v = th.norm(v, dim=-1, keepdim=True)\n",
    "    result = th.tanh(norm_v) / norm_v * v\n",
    "    \n",
    "    return project_hyp_vec(result)\n",
    "\n",
    "\n",
    "def log_map_zero(y):\n",
    "    diff = project_hyp_vec(y + EPS)\n",
    "    norm_diff = th.norm(diff, dim=-1, keepdim=True)\n",
    "    return atanh(norm_diff)/norm_diff*diff\n",
    "\n",
    "\n",
    "def mob_pointwise_prod(x, u):\n",
    "    # x is hyperbolic, u is Euclidean\n",
    "    x = project_hyp_vec(x + EPS)\n",
    "    Mx = x * u\n",
    "    Mx_norm = th.norm(Mx + EPS, dim=-1, keepdim=True)\n",
    "    x_norm = th.norm(x, dim=-1, keepdim=True)\n",
    "\n",
    "    result = th.tanh(Mx_norm / x_norm * atanh(x_norm)) / Mx_norm * Mx\n",
    "    return project_hyp_vec(result)\n",
    "\n",
    "\n",
    "class hyperRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, d_ball):\n",
    "        super(hyperRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.d_ball = d_ball\n",
    "        \n",
    "        k = (1 / hidden_size)**0.5\n",
    "        self.w = gt.ManifoldParameter(gt.ManifoldTensor(hidden_size, d_ball, hidden_size, d_ball).uniform_(-k, k))\n",
    "        self.u = gt.ManifoldParameter(gt.ManifoldTensor(input_size, d_ball, hidden_size, d_ball).uniform_(-k, k))\n",
    "        self.b = gt.ManifoldParameter(gt.ManifoldTensor(hidden_size, d_ball, manifold=gt.PoincareBall()).zero_())\n",
    "        \n",
    "        \n",
    "    def transition(self, x, h):\n",
    "        W_otimes_h = mob_mat_mul_d(self.w, h, self.d_ball)\n",
    "        U_otimes_x = mob_mat_mul_d(self.u, x, self.d_ball)\n",
    "        Wh_plus_Ux = mob_add(W_otimes_h, U_otimes_x)\n",
    "        \n",
    "        return mob_add(Wh_plus_Ux, self.b)\n",
    "    \n",
    "    \n",
    "    def init_rnn_state(self, batch_size, hidden_size, device=cuda_device):\n",
    "        return th.zeros((batch_size, hidden_size, d_ball), dtype=default_dtype, device=cuda_device)\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        hidden = self.init_rnn_state(inputs.shape[0], self.hidden_size)\n",
    "        outputs = []\n",
    "        for x in inputs.transpose(0, 1):\n",
    "            hidden = self.transition(x, hidden)\n",
    "            outputs += [hidden]\n",
    "        return th.stack(outputs).transpose(0, 1)\n",
    "    \n",
    "\n",
    "class GRUCell(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, d_ball):\n",
    "        super(GRUCell, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.d_ball = d_ball\n",
    "        \n",
    "        k = (1 / hidden_size)**0.5\n",
    "        self.w_z = gt.ManifoldParameter(gt.ManifoldTensor(hidden_size, d_ball, hidden_size, d_ball).uniform_(-k, k))\n",
    "        self.w_r = gt.ManifoldParameter(gt.ManifoldTensor(hidden_size, d_ball, hidden_size, d_ball).uniform_(-k, k))\n",
    "        self.w_h = gt.ManifoldParameter(gt.ManifoldTensor(hidden_size, d_ball, hidden_size, d_ball).uniform_(-k, k))\n",
    "        self.u_z = gt.ManifoldParameter(gt.ManifoldTensor(input_size, d_ball, hidden_size, d_ball).uniform_(-k, k))\n",
    "        self.u_r = gt.ManifoldParameter(gt.ManifoldTensor(input_size, d_ball, hidden_size, d_ball).uniform_(-k, k))\n",
    "        self.u_h = gt.ManifoldParameter(gt.ManifoldTensor(input_size, d_ball, hidden_size, d_ball).uniform_(-k, k))\n",
    "        self.b_z = gt.ManifoldParameter(gt.ManifoldTensor(hidden_size, d_ball, manifold=gt.PoincareBall()).zero_())\n",
    "        self.b_r = gt.ManifoldParameter(gt.ManifoldTensor(hidden_size, d_ball, manifold=gt.PoincareBall()).zero_())\n",
    "        self.b_h = gt.ManifoldParameter(gt.ManifoldTensor(hidden_size, d_ball, manifold=gt.PoincareBall()).zero_())\n",
    "        \n",
    "    \n",
    "    def transition(self, W, h, U, x, hyp_b):\n",
    "        W_otimes_h = mob_mat_mul_d(W, h, self.d_ball)\n",
    "        U_otimes_x = mob_mat_mul_d(U, x, self.d_ball)\n",
    "        Wh_plus_Ux = mob_add(W_otimes_h, U_otimes_x)\n",
    "        \n",
    "        return mob_add(Wh_plus_Ux, hyp_b)\n",
    "    \n",
    "    \n",
    "    def forward(self, hyp_x, hidden):\n",
    "        z = self.transition(self.w_z, hidden, self.u_z, hyp_x, self.b_z)\n",
    "        z = th.sigmoid(log_map_zero(z))\n",
    "\n",
    "        r = self.transition(self.w_r, hidden, self.u_r, hyp_x, self.b_r)\n",
    "        r = th.sigmoid(log_map_zero(r))\n",
    "\n",
    "        r_point_h = mob_pointwise_prod(hidden, r)\n",
    "        h_tilde = self.transition(self.w_h, r_point_h, self.u_r, hyp_x, self.b_h)\n",
    "        # h_tilde = th.tanh(log_map_zero(h_tilde)) # non-linearity\n",
    "\n",
    "        minus_h_oplus_htilde = mob_add(-hidden, h_tilde)\n",
    "        new_h = mob_add(hidden, mob_pointwise_prod(minus_h_oplus_htilde, z))\n",
    "        \n",
    "        return new_h\n",
    "    \n",
    "    \n",
    "class hyperGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, d_ball):\n",
    "        super(hyperGRU, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.d_ball = d_ball\n",
    "        \n",
    "        self.gru_cell = GRUCell(input_size, hidden_size, d_ball)\n",
    "    \n",
    "    \n",
    "    def init_gru_state(self, batch_size, hidden_size, device=cuda_device):\n",
    "        return th.zeros((batch_size, hidden_size, self.d_ball), dtype=default_dtype, device=cuda_device)\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        hidden = self.init_gru_state(inputs.shape[0], self.hidden_size)\n",
    "        outputs = []\n",
    "        for x in inputs.transpose(0, 1):\n",
    "            hidden = self.gru_cell(x, hidden)\n",
    "            outputs += [hidden]\n",
    "        return th.stack(outputs).transpose(0, 1)\n",
    "    \n",
    "    \n",
    "class HyperIM(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num, word_embed, label_embed, d_ball, hidden_size=5, if_gru=False, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.d_ball = d_ball\n",
    "        \n",
    "        self.word_embed = gt.ManifoldParameter(word_embed, manifold=gt.PoincareBall())\n",
    "        self.label_embed = gt.ManifoldParameter(label_embed, manifold=gt.PoincareBall())\n",
    "        \n",
    "        if(if_gru):\n",
    "            self.rnn = hyperGRU(input_size=word_embed.shape[1], hidden_size=self.hidden_size, d_ball=self.d_ball)\n",
    "        else:\n",
    "            self.rnn = hyperRNN(input_size=word_embed.shape[1], hidden_size=self.hidden_size, d_ball=self.d_ball)\n",
    "        \n",
    "        self.dense_1 = nn.Linear(feature_num, int(feature_num*2))\n",
    "        self.dense_2 = nn.Linear(int(feature_num*2), 1)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        word_embed = self.word_embed[x]\n",
    "        encode = self.rnn(word_embed)\n",
    "\n",
    "        encode = encode.unsqueeze(dim=2)\n",
    "        encode = encode.expand(-1, -1, self.label_embed.shape[0], -1, -1)\n",
    "        \n",
    "        interaction = poinc_dist(encode, self.label_embed.expand_as(encode))\n",
    "        interaction = interaction.squeeze(dim=-1).sum(dim=-1).transpose(1, 2)\n",
    "        \n",
    "        out = F.relu(self.dense_1(interaction))\n",
    "        out = self.dense_2(out).squeeze(dim=-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embed = th.randn(270734, 128, 8)\n",
    "label_embed = th.randn(35, 128, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HyperIM(50, word_embed, label_embed, d_ball=8, hidden_size=128, if_gru=True)\n",
    "net = net.to(cuda_device)\n",
    "\n",
    "loss = nn.BCEWithLogitsLoss()\n",
    "optim = th.optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(th.load('/data/blchen/text/CCKS2019-IPRE/net/sent/hyper-2.pt', \n",
    "                            map_location=lambda storage, loc: storage.cuda(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_k(pred, label, k=[1, 3, 5]):\n",
    "    batch_size = pred.shape[0]\n",
    "    \n",
    "    precision = []\n",
    "    for _k in k:\n",
    "        p = 0\n",
    "        for i in range(batch_size):\n",
    "            p += label[i, pred[i, :_k]].mean().item()\n",
    "        precision.append(p*100/batch_size)\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def evaluate(result):\n",
    "    p1, p3 = 0, 0\n",
    "    \n",
    "    with th.no_grad():\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(dev_data_loader):\n",
    "\n",
    "            _batch_size = X_batch.shape[0]\n",
    "            X_batch = X_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "\n",
    "            output = net(X_batch)\n",
    "            pred = output.topk(k=5)[1]\n",
    "\n",
    "            _p1, _p3 = precision_k(pred, y_batch, k=[1, 3])\n",
    "            p1 += _p1\n",
    "            p3 += _p3\n",
    "\n",
    "    \n",
    "    batch_idx += 1\n",
    "    p1 /= batch_idx\n",
    "    p3 /= batch_idx\n",
    "\n",
    "    result[-1].append([p1, p3])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# def evaluate(result):\n",
    "#     f, p, r = 0, 0, 0\n",
    "    \n",
    "#     with th.no_grad():\n",
    "#         for batch_idx, (X_batch, y_batch) in enumerate(dev_data_loader):\n",
    "\n",
    "#             _batch_size = X_batch.shape[0]\n",
    "#             X_batch = X_batch.cuda()\n",
    "#             y_batch = y_batch.numpy()\n",
    "\n",
    "#             output = net(X_batch).topk(k=5)[1].cpu().numpy()\n",
    "#             pred = np.zeros(y_batch.shape)\n",
    "#             pred[output] = 1\n",
    "\n",
    "#             _f = f1_score(y_batch, pred, average='micro')\n",
    "#             _p = precision_score(y_batch, pred, average='micro')\n",
    "#             _r = recall_score(y_batch, pred, average='micro')\n",
    "#             f += _f\n",
    "#             p += _p\n",
    "#             r += _r\n",
    "\n",
    "    \n",
    "#     batch_idx += 1\n",
    "#     f /= batch_idx\n",
    "#     p /= batch_idx\n",
    "#     r /= batch_idx\n",
    "\n",
    "#     result[-1].append([f, p, r])\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in tqdm(range(3, 11)):\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(train_data_loader):\n",
    "        \n",
    "        X_batch = X_batch.cuda()\n",
    "        y_batch = y_batch.cuda()\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        l = loss(net(X_batch), y_batch)\n",
    "        l.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    result.append(['epoch', e])\n",
    "    result = evaluate(result)\n",
    "    \n",
    "    th.save(net.state_dict(), '/data/blchen/text/CCKS2019-IPRE/net/sent/hyper-'+ str(e) + '.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(os.path.join(save_path, 'X_test.npy'))\n",
    "X_test = th.LongTensor(X_test)\n",
    "\n",
    "test_data_loader = th.utils.data.DataLoader(X_test, batch_size=4)\n",
    "\n",
    "for X_test_batch in test_data_loader:\n",
    "    print('X_train shape', X_test_batch.shape)\n",
    "    break\n",
    "print('train_batch_num', len(test_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "with th.no_grad():\n",
    "    for batch_idx, X_batch in enumerate(test_data_loader):\n",
    "\n",
    "        _batch_size = X_batch.shape[0]\n",
    "        X_batch = X_batch.cuda()\n",
    "\n",
    "        output = net(X_batch)\n",
    "        pred = output.topk(k=1)[1]\n",
    "        for p in pred.tolist():\n",
    "            result.append(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in result:\n",
    "    if(r != 0):\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_path, 'r') as f:\n",
    "    with open(os.path.join(result_path, 'result-hyper-2.txt'), 'w') as fw:\n",
    "        cnt = 0\n",
    "        for line in f:\n",
    "            fw.write(line.strip() + '\\t' + str(result[cnt]) + '\\n')\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
