{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "TRAIN_SENTENCE_PATH = \"dataset/sentTrain.txt\"\n",
    "TRAIN_BAG_PATH = \"dataset/bag_relation_train.txt\"\n",
    "DEV_SENTENSE_PATH = \"dataset/sentDev.txt\"\n",
    "DEV_BAG_PATH = \"dataset/bag_relation_dev.txt\"\n",
    "TEST_SENTENSE_PATH = \"dataset/sent_test.txt\"\n",
    "TEST_BAG_PATH = \"dataset/bag_relation_test.txt\"\n",
    "EMMBEDDING_LEN = 200\n",
    "train_Sentense = []\n",
    "train_Bag = []\n",
    "dev_Sentense = []\n",
    "dev_Bag = []\n",
    "test_Sentense = []\n",
    "test_Bag = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentense:\n",
    "    def __init__(self, info, location):\n",
    "        self.personA = info[1]\n",
    "        self.personB = info[2]\n",
    "        self.sentense = info[3].split(\" \")\n",
    "        self.sentense_emm = np.zeros((len(self.sentense),EMMBEDDING_LEN))\n",
    "        if location != \"test\":\n",
    "            self.id = int(info[4].split('_')[3])\n",
    "        else:\n",
    "            self.id = int(info[0].split('_')[3])            \n",
    "        if location != \"test\":\n",
    "            self.relation = []\n",
    "            for label in info[5].rstrip().split(\" \"):\n",
    "                self.relation.append(int(label))\n",
    "            \n",
    "class Bag:\n",
    "    def __init__(self, info, location):\n",
    "        self.id = info[0].split('_')[3]\n",
    "        self.personA = info[1]\n",
    "        self.personB = info[2]\n",
    "        self.Sentenses = []\n",
    "        for sen_id in info[3].split(' '):\n",
    "            sen_id = int(sen_id.split(\"_\")[3]) - 1\n",
    "            if location == \"train\":\n",
    "                self.Sentenses.append(train_Sentense[sen_id])\n",
    "            elif location == \"dev\":\n",
    "                self.Sentenses.append(dev_Sentense[sen_id])\n",
    "            elif location == \"test\":\n",
    "                self.Sentenses.append(test_Sentense[sen_id])\n",
    "        if location != \"test\":\n",
    "            self.relation = []\n",
    "            for label in info[4].rstrip().split(\" \"):\n",
    "                self.relation.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_SENTENCE_PATH) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        info = line.split(\"\\t\")\n",
    "        tmp = Sentense(info, \"train\")\n",
    "        train_Sentense.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_BAG_PATH) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        info = line.split('\\t')\n",
    "        tmp = Bag(info,\"train\")\n",
    "        train_Bag.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287351, 37948)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Sentense),len(train_Bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[248850,\n",
       " 8142,\n",
       " 218,\n",
       " 183,\n",
       " 5544,\n",
       " 245,\n",
       " 69,\n",
       " 291,\n",
       " 40,\n",
       " 9,\n",
       " 6870,\n",
       " 1383,\n",
       " 2627,\n",
       " 830,\n",
       " 46,\n",
       " 19,\n",
       " 1673,\n",
       " 637,\n",
       " 532,\n",
       " 805,\n",
       " 77,\n",
       " 77,\n",
       " 22,\n",
       " 158,\n",
       " 30,\n",
       " 13,\n",
       " 119,\n",
       " 67,\n",
       " 24,\n",
       " 165,\n",
       " 1610,\n",
       " 1301,\n",
       " 1266,\n",
       " 2911,\n",
       " 547]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_NA = []\n",
    "tmp = [0 for i in range(35)]\n",
    "for sen in train_Sentense:\n",
    "    for r in sen.relation:\n",
    "        tmp[r]+=1\n",
    "        if r == 0:\n",
    "            sen_NA.append(sen)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DEV_SENTENSE_PATH) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        info = line.split(\"\\t\")\n",
    "        tmp = Sentense(info, \"train\")\n",
    "        dev_Sentense.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DEV_BAG_PATH) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        info = line.split('\\t')\n",
    "        tmp = Bag(info,\"dev\")\n",
    "        dev_Bag.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38417, 5416)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_Sentense),len(dev_Bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_SENTENSE_PATH) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        info = line.split(\"\\t\")\n",
    "        tmp = Sentense(info, \"test\")\n",
    "        test_Sentense.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEST_BAG_PATH) as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        info = line.split('\\t')\n",
    "        tmp = Bag(info,\"test\")\n",
    "        test_Bag.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77092, 10849)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_Sentense),len(test_Bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有切分后的句子，用于训练词向量\n",
    "sentenses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Sentense in (train_Sentense+dev_Sentense+test_Sentense):\n",
    "    sentenses.append(Sentense.sentense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402860"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec \n",
    "# model = Word2Vec(sentenses, sg=1, size=EMMBEDDING_LEN, window=5, min_count=1, negative=3)\n",
    "# model.save(\"CCKS_2019\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec \n",
    "model = Word2Vec.load(\"/Users/denhiroshi/Downloads/model_data/CCKS_2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 0\n",
    "for Sentense in(train_Sentense+dev_Sentense+test_Sentense):\n",
    "    sentense_emm = []\n",
    "    for i in range(len(Sentense.sentense)):\n",
    "        tmp = Sentense.sentense[i]\n",
    "        sentense_emm.append(model[tmp])\n",
    "    Sentense.sentense_emm = np.stack(sentense_emm)\n",
    "    MAX_LEN = max(MAX_LEN, len(Sentense.sentense_emm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for Sentense in(train_Sentense+dev_Sentense+test_Sentense):\n",
    "    if len(Sentense.sentense_emm) < MAX_LEN:\n",
    "        need = MAX_LEN - len(Sentense.sentense_emm)\n",
    "        need = np.zeros((need, EMMBEDDING_LEN))\n",
    "        Sentense.sentense_emm = np.concatenate((Sentense.sentense_emm, need), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Sentense[0].sentense_emm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sen_NA = []\n",
    "# for Sentense in train_Sentense:\n",
    "#     if 0 in Sentense.relation:\n",
    "#         sen_NA.append(Sentense.sentense_emm)\n",
    "\n",
    "# sen_NA = np.stack(sen_NA)\n",
    "# np.save('/Users/denhiroshi/Downloads/model_data/train_NA.npy',sen_NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机取样3K条无关系数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_NA = np.load('/Users/denhiroshi/Downloads/model_data/train_NA.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSENUMS = 5000\n",
    "indexs = np.random.choice(sen_NA.shape[0], CHOOSENUMS, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 50, 200)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_NA = sen_NA[indexs]\n",
    "sen_NA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Sentense_np = []\n",
    "for Sentense in train_Sentense:\n",
    "    if 0 in Sentense.relation:\n",
    "        continue\n",
    "    train_Sentense_np.append(Sentense.sentense_emm)\n",
    "train_Sentense_np = np.stack(train_Sentense_np)\n",
    "train_Sentense_np = np.concatenate((train_Sentense_np, sen_NA), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_Sentense_np = []\n",
    "for Sentense in dev_Sentense:\n",
    "    dev_Sentense_np.append(Sentense.sentense_emm)\n",
    "dev_Sentense_np = np.stack(dev_Sentense_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Sentense_np = []\n",
    "for Sentense in test_Sentense:\n",
    "    test_Sentense_np.append(Sentense.sentense_emm)\n",
    "test_Sentense_np = np.stack(test_Sentense_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_Sentense_np.npy',train_Sentense_np)\n",
    "np.save('dev_Sentense_np.npy',dev_Sentense_np)\n",
    "np.save('test_Sentense_np.npy',test_Sentense_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RELATION_LEN = 0\n",
    "MU = 0 \n",
    "for Sentense in(train_Sentense+dev_Sentense):\n",
    "    Sentense.relation = np.stack(Sentense.relation)\n",
    "    MAX_RELATION_LEN = max(MAX_RELATION_LEN, len(Sentense.relation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_RELATION_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "MU = 0 \n",
    "for Sentense in(train_Sentense+dev_Sentense):\n",
    "    if len(Sentense.relation) == MAX_RELATION_LEN:\n",
    "        MU+=1\n",
    "    else:\n",
    "        need = MAX_RELATION_LEN - len(Sentense.relation)\n",
    "        tmp = [-1 for i in range(need)]\n",
    "        tmp = np.array(tmp)\n",
    "        Sentense.relation = np.concatenate((Sentense.relation,tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Sentense[0].relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Relation_np = []\n",
    "for Sentense in train_Sentense:\n",
    "    if 0 in Sentense.relation:\n",
    "        continue\n",
    "    train_Relation_np.append(Sentense.relation)\n",
    "train_Relation_np = np.stack(train_Relation_np)\n",
    "train_Relation_np = np.concatenate((train_Relation_np, np.array([[0,-1] for i in range(CHOOSENUMS)])), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_Relation_np = []\n",
    "for Sentense in dev_Sentense:\n",
    "    dev_Relation_np.append(Sentense.relation)\n",
    "dev_Relation_np = np.stack(dev_Relation_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_Relation_np.npy',train_Relation_np)\n",
    "np.save('dev_Relation_np.npy',dev_Relation_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sentense_explain.txt\",'w') as f:\n",
    "    f.write(\"train_Sentense_np: \"+str(len(train_Sentense))+'*'+str(MAX_LEN)+'*200\\n')\n",
    "    f.write(\"dev_Sentense_np: \"+str(len(dev_Sentense))+'*'+str(MAX_LEN)+'*200\\n')\n",
    "    f.write(\"test_Sentense_np: \"+str(len(test_Sentense))+'*'+str(MAX_LEN)+'*200\\n')\n",
    "    f.write(\"Relation属性为-1表示为填充\\n\")\n",
    "    f.write(\"train_Relation_np: \"+str(len(train_Sentense))+'*'+str(MAX_RELATION_LEN)+'\\n')\n",
    "    f.write(\"dev_Relation_np: \"+str(len(dev_Sentense))+'*'+str(MAX_RELATION_LEN)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43501, 50, 200), (38417, 50, 200), (77092, 50, 200))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Sentense_np.shape, dev_Sentense_np.shape, test_Sentense_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43501, 2), (38417, 2))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Relation_np.shape, dev_Relation_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
