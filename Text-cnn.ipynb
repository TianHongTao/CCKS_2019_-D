{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import logging\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from sklearn import preprocessing\n",
    "from random import shuffle\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 401\n",
    "LABELNUMS = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_hot(data1):\n",
    "    return (np.arange(LABELNUMS)==data1[:,None]).astype(np.integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.from_numpy(np.load(\"train_Sentense_np.npy\").astype(\"float32\"))\n",
    "train_Y = np.load(\"train_Relation_np.npy\").astype(\"int32\")\n",
    "dev_X = torch.from_numpy(np.load(\"dev_Sentense_np.npy\").astype(\"float32\"))\n",
    "dev_Y = np.load(\"dev_Relation_np.npy\").astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = train_Y.tolist()\n",
    "dev_Y = dev_Y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([43501, 35])\n",
      "torch.Size([38417, 35])\n"
     ]
    }
   ],
   "source": [
    "# OneHot\n",
    "train_ontHot_y = []\n",
    "dev_ontHot_y = []\n",
    "for trainY in train_Y:\n",
    "    tmp = np.eye(LABELNUMS)[trainY]\n",
    "    tmp = tmp.sum(axis = 0).astype(\"int32\")\n",
    "    tmp = tmp[:-1]\n",
    "    train_ontHot_y.append(tmp)\n",
    "train_ontHot_y = torch.Tensor(train_ontHot_y)\n",
    "print(train_ontHot_y.shape)\n",
    "for devY in dev_Y:\n",
    "    tmp = np.eye(LABELNUMS)[devY]\n",
    "    tmp = tmp.sum(axis = 0).astype(\"int32\")\n",
    "    tmp = tmp[:-1]\n",
    "    dev_ontHot_y.append(tmp)\n",
    "dev_ontHot_y = torch.Tensor(dev_ontHot_y)\n",
    "print(dev_ontHot_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "class TEXTCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TEXTCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, BATCH_SIZE, 200)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=(1,200),\n",
    "            ), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(50,1)), \n",
    "        )\n",
    "        \n",
    "        self.conv2 = nn.Sequential( \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=(3,200), \n",
    "            ), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=(48,1)), \n",
    "        )\n",
    "        \n",
    "        self.conv3 = nn.Sequential( \n",
    "            nn.Conv2d(\n",
    "                in_channels=1, \n",
    "                out_channels=16, \n",
    "                kernel_size=(5,200), \n",
    "                stride = 1,\n",
    "            ), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(46,1)),\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Linear(48, LABELNUMS-1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape((-1,1,x.shape[1],x.shape[2]))\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x = torch.cat((x1,x2,x3),1)\n",
    "        x = x.view(x.size(0), -1)   # 展平\n",
    "#         x = self.out(x)\n",
    "        output = self.output(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To GPU\n"
     ]
    }
   ],
   "source": [
    "model = TEXTCNN()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"To GPU\")\n",
    "    train_X = train_X.cuda()\n",
    "    train_ontHot_y = train_ontHot_y.cuda()\n",
    "    dev_X = dev_X.cuda()\n",
    "    dev_ontHot_y = dev_ontHot_y.cuda()\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    print(\"Still CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(train_X, train_ontHot_y)\n",
    "dev = TensorDataset(dev_X, dev_ontHot_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset = train, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True,\n",
    "    num_workers = 0, \n",
    ")\n",
    "\n",
    "\n",
    "dev_loader = DataLoader(\n",
    "    dataset = dev, \n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True, \n",
    "    num_workers = 0, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: accuracy:0.49992743808049533 loss: 0.055103663355112076 time: 4.840629816055298\n",
      "2: accuracy:0.4867922189434985 loss: 0.053623706102371216 time: 4.857752561569214\n",
      "3: accuracy:0.46971900396671823 loss: 0.05323966592550278 time: 4.895254850387573\n",
      "4: accuracy:0.4269271236455109 loss: 0.05292476713657379 time: 4.868378400802612\n",
      "5: accuracy:0.5339982827012384 loss: 0.052359458059072495 time: 4.868848562240601\n",
      "6: accuracy:0.3503954624613003 loss: 0.05188378691673279 time: 4.861184358596802\n",
      "7: accuracy:0.5069311750193498 loss: 0.051628097891807556 time: 4.855306386947632\n",
      "8: accuracy:0.457820360874613 loss: 0.05127422884106636 time: 4.89635157585144\n",
      "9: accuracy:0.4732201165828173 loss: 0.05089668557047844 time: 4.894102573394775\n",
      "10: accuracy:0.5353119557856038 loss: 0.05054175481200218 time: 4.819168567657471\n",
      "11: accuracy:0.4878232028831269 loss: 0.050170574337244034 time: 4.832513332366943\n",
      "12: accuracy:0.5304518188854489 loss: 0.04991067945957184 time: 4.882385730743408\n",
      "13: accuracy:0.4679518188854489 loss: 0.04953404515981674 time: 4.952599287033081\n",
      "14: accuracy:0.4694453850619195 loss: 0.049510687589645386 time: 4.945807933807373\n",
      "15: accuracy:0.4535376959171827 loss: 0.04932703077793121 time: 5.015902280807495\n",
      "16: accuracy:0.5238305437306502 loss: 0.04873666167259216 time: 5.262273788452148\n",
      "17: accuracy:0.4832366848877709 loss: 0.04860050231218338 time: 4.8464226722717285\n",
      "18: accuracy:0.5768990059017028 loss: 0.04843856021761894 time: 4.901061296463013\n",
      "19: accuracy:0.49076196062306504 loss: 0.04834446683526039 time: 4.837008714675903\n",
      "20: accuracy:0.5673042037538699 loss: 0.04844732955098152 time: 4.830706834793091\n",
      "21: accuracy:0.4682405548568111 loss: 0.048076216131448746 time: 4.904736042022705\n",
      "22: accuracy:0.42873814821981426 loss: 0.047899845987558365 time: 4.869883298873901\n",
      "23: accuracy:0.47861993275928794 loss: 0.047811005264520645 time: 4.868468761444092\n",
      "24: accuracy:0.4966273824496904 loss: 0.047410763800144196 time: 4.864940643310547\n",
      "25: accuracy:0.5215856593459752 loss: 0.04711414873600006 time: 4.863373041152954\n",
      "26: accuracy:0.5063491679566564 loss: 0.04739033430814743 time: 4.876792669296265\n",
      "27: accuracy:0.5052788796439628 loss: 0.046883195638656616 time: 4.951058864593506\n",
      "28: accuracy:0.45910228811919507 loss: 0.04682162031531334 time: 4.883056640625\n",
      "29: accuracy:0.5525907628676471 loss: 0.04670159891247749 time: 4.896743535995483\n",
      "30: accuracy:0.48061840895897834 loss: 0.04663349688053131 time: 4.838539361953735\n",
      "31: accuracy:0.47743475474071206 loss: 0.04641200602054596 time: 4.908064365386963\n",
      "32: accuracy:0.5655884166989164 loss: 0.046425748616456985 time: 4.868293285369873\n",
      "33: accuracy:0.46066690450851394 loss: 0.046365439891815186 time: 4.885233640670776\n",
      "34: accuracy:0.503570651122291 loss: 0.04609571769833565 time: 4.857144117355347\n",
      "35: accuracy:0.48902803308823534 loss: 0.0458967424929142 time: 4.889391183853149\n",
      "36: accuracy:0.5365167859907121 loss: 0.04601351171731949 time: 4.865662097930908\n",
      "37: accuracy:0.47039020172213625 loss: 0.04566759988665581 time: 4.862709283828735\n",
      "38: accuracy:0.5380587267801857 loss: 0.04565098509192467 time: 4.889805555343628\n",
      "39: accuracy:0.5394464734907121 loss: 0.045582786202430725 time: 4.872713565826416\n",
      "40: accuracy:0.5307435782701239 loss: 0.04537626728415489 time: 4.888141632080078\n",
      "41: accuracy:0.5516338525541795 loss: 0.045389171689748764 time: 5.027397155761719\n",
      "42: accuracy:0.526593943498452 loss: 0.04524343088269234 time: 4.899687051773071\n",
      "43: accuracy:0.49849131675696595 loss: 0.045145343989133835 time: 4.881211757659912\n",
      "44: accuracy:0.49544069272445823 loss: 0.04511062055826187 time: 4.851530313491821\n",
      "45: accuracy:0.47656401170665635 loss: 0.044797684997320175 time: 4.830442190170288\n",
      "46: accuracy:0.5423338332043344 loss: 0.0448119230568409 time: 4.820651292800903\n",
      "47: accuracy:0.46810601296439625 loss: 0.04479619488120079 time: 4.847289800643921\n",
      "48: accuracy:0.4625640963622291 loss: 0.044905923306941986 time: 4.852478265762329\n",
      "49: accuracy:0.5549611189047987 loss: 0.044585615396499634 time: 4.84719181060791\n",
      "50: accuracy:0.5711877781540248 loss: 0.044560953974723816 time: 4.827172040939331\n",
      "51: accuracy:0.4831550527283282 loss: 0.04452713206410408 time: 4.86375617980957\n",
      "52: accuracy:0.43268067917956654 loss: 0.04452250525355339 time: 4.846971273422241\n",
      "53: accuracy:0.4608044698142415 loss: 0.0444917231798172 time: 4.905468940734863\n",
      "54: accuracy:0.5039395075464397 loss: 0.04419038072228432 time: 4.815981388092041\n",
      "55: accuracy:0.4842087122678019 loss: 0.04417668655514717 time: 4.831593751907349\n",
      "56: accuracy:0.48237501209365324 loss: 0.04436058923602104 time: 4.849572658538818\n",
      "57: accuracy:0.4668180388931889 loss: 0.04393382370471954 time: 4.862152814865112\n",
      "58: accuracy:0.4997021937886997 loss: 0.04387422278523445 time: 4.8742780685424805\n",
      "59: accuracy:0.5115721144543344 loss: 0.04376351088285446 time: 4.824416637420654\n",
      "60: accuracy:0.5383187403250774 loss: 0.04379769414663315 time: 4.891658544540405\n",
      "61: accuracy:0.4576147687693498 loss: 0.043740641325712204 time: 4.898065090179443\n",
      "62: accuracy:0.5379272083010836 loss: 0.04358091950416565 time: 4.874876499176025\n",
      "63: accuracy:0.5091276847910217 loss: 0.04376594349741936 time: 5.049681901931763\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-09a24ebb014a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_F\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2026\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2027\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "loss_F = torch.nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "for epoch in range(1,EPOCHS): \n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    #print(\"1\")\n",
    "    for step,(x,y) in enumerate(train_loader):\n",
    "        predict = model(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_F(sigmoid(predict), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.mean())\n",
    "    #print(\"2\")\n",
    "    with torch.no_grad():\n",
    "        accs = []\n",
    "        for step,(devx,devy) in enumerate(dev_loader):\n",
    "            dev_pred = model(devx)\n",
    "            dev_pred = sigmoid(dev_pred)\n",
    "            tmp = dev_pred > 0.5\n",
    "            count = 0\n",
    "            for i in range(tmp.shape[0]):\n",
    "                if torch.sum(tmp.int()[i] == devy.int()[i]).tolist() == devy.shape[1]:\n",
    "                    count+=1\n",
    "            acc = count / devy.shape[0]\n",
    "            accs.append(acc)\n",
    "        print(f\"{epoch}: accuracy:{sum(accs)/len(accs)} loss: {torch.mean(torch.stack(losses))} time: {time.time() - start}\")\n",
    "    #print(\"flag\")\n",
    "    #assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
